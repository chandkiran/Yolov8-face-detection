{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"K:/fine_tuned/runs/kaggle/working/runs/detect/train2/weights/best.pt\")  # Replace with your YOLO model path\n",
    "\n",
    "# Load known face encodings (initially empty)\n",
    "reference_face_encoding = None\n",
    "recognition_threshold = 0.6  # Adjust this threshold as needed\n",
    "\n",
    "# Function to play a sound\n",
    "def play_sound(filename):\n",
    "    os.system(f'start {filename}')  # Works on Windows\n",
    "\n",
    "def process_frame(frame):\n",
    "    global reference_face_encoding, recognition_done, tracker, tracking\n",
    "    \n",
    "    # Convert the frame to RGB (YOLO model expects RGB images)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform YOLO object detection\n",
    "    results = model(rgb_frame)\n",
    "    \n",
    "    face_boxes = []\n",
    "\n",
    "    # Annotate the frame with bounding boxes\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            confidence = box.conf[0]\n",
    "            class_id = int(box.cls[0])\n",
    "            class_name = model.names[class_id] if hasattr(model, 'names') else f\"Class {class_id}\"\n",
    "\n",
    "            # Store face box coordinates\n",
    "            face_boxes.append((x1, y1, x2, y2))\n",
    "            \n",
    "            if reference_face_encoding is not None:\n",
    "                detected_face_image = frame[y1:y2, x1:x2]\n",
    "                if detected_face_image.size > 0:\n",
    "                    detected_face_image_rgb = cv2.cvtColor(detected_face_image, cv2.COLOR_BGR2RGB)\n",
    "                    encodings = face_recognition.face_encodings(detected_face_image_rgb)\n",
    "                    if encodings:\n",
    "                        detected_face_encoding = encodings[0]\n",
    "                        face_distance = face_recognition.face_distance([reference_face_encoding], detected_face_encoding)[0]\n",
    "                        if face_distance < recognition_threshold:\n",
    "                            # Initialize tracker for the matching face\n",
    "                            tracker = cv2.TrackerKCF_create()\n",
    "                            tracker.init(frame, (x1, y1, x2 - x1, y2 - y1))\n",
    "                            tracking = True\n",
    "                            recognition_done = True\n",
    "                            cv2.putText(frame, \"Face Matched\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                            play_sound(\"match_sound.mp3\")  # Play a sound on match\n",
    "                            break\n",
    "\n",
    "            # Draw rectangle\n",
    "            color = (0, 255, 0)  # Green for untracked faces\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            # Draw label\n",
    "            label = f\"{class_name} {confidence:.2f}\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return frame\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
